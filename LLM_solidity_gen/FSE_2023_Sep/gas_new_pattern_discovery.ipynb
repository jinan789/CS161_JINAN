{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9fb5f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinanjiang/miniconda3/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6229f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(contents, path):\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021bf369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7504453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_new_gas_pattern(target_codes, use_cache = False, save_dialogue = False, cache_prefix = 'cache/', collection_mode = False):\n",
    "    cache_path = cache_prefix\n",
    "    \n",
    "    if use_cache and not collection_mode:\n",
    "        if os.path.exists(cache_path):\n",
    "            return read_from_file(cache_path)\n",
    "        \n",
    "    source_files_lst = []\n",
    "    \n",
    "    l = []\n",
    "    # source_files_lst.append(['prompts_folder/summarize_contracts.txt', \"ERC20.sol\"])\n",
    "    l.extend(['gas_new_pattern_prompts/' + 'new_pattern_discovery' + '.txt', GPT_string(target_codes)])\n",
    "    \n",
    "    source_files_lst.append(l)\n",
    "\n",
    "    if save_dialogue:\n",
    "        gpt, all_responses_lst = do_pipeline(source_files_lst, output_file_path = get_filename_from_path(contract_file_name) + '_relevant_contracts', do_print = True)\n",
    "    else:\n",
    "        gpt, all_responses_lst = do_pipeline(source_files_lst, output_file_path = None, do_print = True)\n",
    "\n",
    "    assert len(all_responses_lst) == 1\n",
    "    \n",
    "    if use_cache:\n",
    "        # assert not os.path.exists(cache_path)\n",
    "        content = all_responses_lst[0]\n",
    "        content += '\\n*****&&&&&^^^^^%%%%%$$$$$\\n\\n\\n'\n",
    "        write_to_file(content, cache_path)\n",
    "        \n",
    "    return all_responses_lst[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b604d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "239efd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_file(path):\n",
    "    with open(path) as f:\n",
    "        return ''.join(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4b16a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bdccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=text.get_text()# 转成string返回给result  因为write只能写string\n",
    "#filename = 'crawled_codes/contract_'+str(count) + '_sourceCode.sol'\n",
    "\n",
    "target_contract_address = url.split('address/')[1].split('#code')[0]\n",
    "assert target_contract_address.startswith('0x')\n",
    "\n",
    "\n",
    "filename = 'crawled_codes/' + cur_date + '/' + target_contract_address + '.txt'\n",
    "if os.path.exists(filename):\n",
    "    cur_num = 0\n",
    "    while True:\n",
    "        filename = 'crawled_codes/' + cur_date + '_duplicates' + '/' + target_contract_address + '_NUMBER' + str(cur_num) + '.txt'\n",
    "        if not os.path.exists(filename):\n",
    "            break\n",
    "        else:\n",
    "            cur_num += 1\n",
    "\n",
    "\n",
    "#assert not os.path.exists(filename)\n",
    "count=count+1\n",
    "\n",
    "with open(filename, 'w',encoding='utf-8') as file_object:\n",
    "     file_object.write(str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4afbacff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True crawled_codes/test/0x4ca725d446ece6e3ffd3e072a6f2a6a16ca492d0_NUMBER0.txt\n",
      "True crawled_codes/test/0x29d078c18e73976710935e6789eb7a0151af7acd_NUMBER0.txt\n",
      "True crawled_codes/test/0xcc5a1fb2999e5232310d15ef667ac5d4a5181258_NUMBER0.txt\n",
      "True crawled_codes/test/0x340de5cb9b177ff1e3d00e6aa3082f979fca621e_NUMBER0.txt\n",
      "True crawled_codes/test/0x1892038be4bd3968f4a8574593032d61c88dcacb_NUMBER0.txt\n",
      "True crawled_codes/test/0xf7D8830C17EeFAaB3A7f9c785Dccd87e2f9f1ACf_NUMBER0.txt\n",
      "True crawled_codes/test/0x0ea42b1562a38fd093de0d330c2c57ab920fd76f_NUMBER0.txt\n",
      "True crawled_codes/test/0xaeb3ac179bd0108fa8eede867dc0b39f29bfc9c2_NUMBER0.txt\n",
      "True crawled_codes/test/0x331c27d9daf6d8f6a2dbf3c16b5c5733da1b4431_NUMBER0.txt\n",
      "True crawled_codes/test/0x2cd33d3dc4d6ea24b6941e4741f4bf4772929e83_NUMBER0.txt\n"
     ]
    }
   ],
   "source": [
    "# with api broken...\n",
    "\n",
    "folder_name_to_list = 'test'\n",
    "all_files_path_under_folder = os.listdir('crawled_codes/' + folder_name_to_list)\n",
    "\n",
    "for cur_file_path in all_files_path_under_folder[:10]:\n",
    "    \n",
    "    target_codes_path = 'crawled_codes/' + folder_name_to_list + '/' + cur_file_path\n",
    "    target_codes = read_from_file(target_codes_path)\n",
    "    \n",
    "    print(os.path.exists(target_codes_path), target_codes_path)\n",
    "    \n",
    "    prefix = read_from_file('gas_new_pattern_prompts/' + 'new_pattern_discovery' + '.txt')\n",
    "    postfix = read_from_file('gas_new_pattern_prompts/' +  'new_pattern_discovery_postfix.txt')\n",
    "    \n",
    "#     append_texts = '\\n'\n",
    "    append_texts = prefix + '\\n' + target_codes + '\\n' + postfix\n",
    "    \n",
    "    func_name = cur_file_path.split('.txt')[0]\n",
    "    gas_pattern_path = 'api_broken/cache/' + 'Q_' + func_name + '.txt'\n",
    "    answer_path = 'api_broken/answers_cache/' + 'A_' + func_name + '.txt'\n",
    "    \n",
    "    if os.path.exists(gas_pattern_path):\n",
    "        cur_num = 0\n",
    "        while True:\n",
    "            gas_pattern_path = 'api_broken/duplicates_cache/Q_' + func_name + '_N' + str(cur_num) + '.txt'\n",
    "            answer_path = 'api_broken/answers_duplicates_cache/' + 'A_' + func_name + '_N' + str(cur_num) + '.txt'\n",
    "\n",
    "            if not os.path.exists(gas_pattern_path):\n",
    "                break\n",
    "            else:\n",
    "                cur_num += 1\n",
    "        \n",
    "            \n",
    "    write_to_file(append_texts, gas_pattern_path)\n",
    "    if not os.path.exists(answer_path):\n",
    "        write_to_file('', answer_path)\n",
    "    else:\n",
    "        print('Q does not exist but A does: ', answer_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b94a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb02d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea8653f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588a4956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d4a3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a8a6693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "Invalid response object from API: '{ \"statusCode\": 500, \"message\": \"Internal server error\", \"activityId\": \"0b4f4b08-ab75-4a6b-982e-77389594127d\" }' (HTTP response code was 500)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/openai/api_requestor.py:331\u001b[0m, in \u001b[0;36mAPIRequestor.handle_error_response\u001b[0;34m(self, rbody, rcode, resp, rheaders, stream_error)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     error_data \u001b[38;5;241m=\u001b[39m \u001b[43mresp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43merror\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'error'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(gas_pattern_path):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre cache_used\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m _, cache_used \u001b[38;5;241m=\u001b[39m \u001b[43mdiscover_new_gas_pattern\u001b[49m\u001b[43m(\u001b[49m\u001b[43mappend_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_prefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgas_pattern_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     _, cache_used \u001b[38;5;241m=\u001b[39m discover_new_gas_pattern(append_texts, use_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, cache_prefix \u001b[38;5;241m=\u001b[39m gas_pattern_path, collection_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn [3], line 19\u001b[0m, in \u001b[0;36mdiscover_new_gas_pattern\u001b[0;34m(target_codes, use_cache, save_dialogue, cache_prefix, collection_mode)\u001b[0m\n\u001b[1;32m     17\u001b[0m     gpt, all_responses_lst \u001b[38;5;241m=\u001b[39m do_pipeline(source_files_lst, output_file_path \u001b[38;5;241m=\u001b[39m get_filename_from_path(contract_file_name) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_relevant_contracts\u001b[39m\u001b[38;5;124m'\u001b[39m, do_print \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     gpt, all_responses_lst \u001b[38;5;241m=\u001b[39m \u001b[43mdo_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_files_lst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_print\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_responses_lst) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# assert not os.path.exists(cache_path)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/LLM_solidity_gen/FSE_2023_Sep/utils.py:108\u001b[0m, in \u001b[0;36mdo_pipeline\u001b[0;34m(source_files_lst, output_file_path, do_print)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m         cur_prompt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m get_prompt_text_from_file(cur_file)\n\u001b[0;32m--> 108\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mgpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m all_responses_lst\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[1;32m    111\u001b[0m cur_print(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m***PROMPT:\u001b[39m\u001b[38;5;124m'\u001b[39m, cur_prompt)\n",
      "File \u001b[0;32m~/Documents/LLM_solidity_gen/FSE_2023_Sep/utils.py:36\u001b[0m, in \u001b[0;36mChatGPT.get_response\u001b[0;34m(self, prompt, is_trivial)\u001b[0m\n\u001b[1;32m     32\u001b[0m     new_context_messages \u001b[38;5;241m=\u001b[39m new_context_messages \u001b[38;5;241m+\u001b[39m [response_d]\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gpt_response, new_context_messages\n\u001b[0;32m---> 36\u001b[0m gpt_response, context_messages \u001b[38;5;241m=\u001b[39m \u001b[43mget_response_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_messages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_messages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_of_contexts: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_of_contexts)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_trivial:\n",
      "File \u001b[0;32m~/Documents/LLM_solidity_gen/FSE_2023_Sep/utils.py:28\u001b[0m, in \u001b[0;36mChatGPT.get_response.<locals>.get_response_inner\u001b[0;34m(prompt, context_messages)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     new_context_messages \u001b[38;5;241m=\u001b[39m context_messages \u001b[38;5;241m+\u001b[39m [d]\n\u001b[0;32m---> 28\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchatgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_context_messages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m gpt_response \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     31\u001b[0m response_d \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: gpt_response}\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    626\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_error_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_error\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/openai/api_requestor.py:333\u001b[0m, in \u001b[0;36mAPIRequestor.handle_error_response\u001b[0;34m(self, rbody, rcode, resp, rheaders, stream_error)\u001b[0m\n\u001b[1;32m    331\u001b[0m     error_data \u001b[38;5;241m=\u001b[39m resp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mAPIError(\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid response object from API: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m (HTTP response code \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwas \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (rbody, rcode),\n\u001b[1;32m    336\u001b[0m         rbody,\n\u001b[1;32m    337\u001b[0m         rcode,\n\u001b[1;32m    338\u001b[0m         resp,\n\u001b[1;32m    339\u001b[0m     )\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternal_message\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_data:\n\u001b[1;32m    342\u001b[0m     error_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m error_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternal_message\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mAPIError\u001b[0m: Invalid response object from API: '{ \"statusCode\": 500, \"message\": \"Internal server error\", \"activityId\": \"0b4f4b08-ab75-4a6b-982e-77389594127d\" }' (HTTP response code was 500)"
     ]
    }
   ],
   "source": [
    "failed_lst_399023 = []\n",
    "folder_name_to_list = 'test'\n",
    "all_files_path_under_folder = os.listdir('crawled_codes/' + folder_name_to_list)\n",
    "\n",
    "for cur_file_path in all_files_path_under_folder[:5]:\n",
    "    \n",
    "    target_codes_path = 'crawled_codes/' + folder_name_to_list + '/' + cur_file_path\n",
    "    target_codes = read_from_file(target_codes_path)\n",
    "    \n",
    "    print(os.path.exists(target_codes_path))\n",
    "    postfix = read_from_file('gas_new_pattern_prompts/' +  'new_pattern_discovery_postfix.txt')\n",
    "\n",
    "    \n",
    "    append_texts = '\\n'\n",
    "    append_texts += target_codes + '\\n' + postfix\n",
    "    \n",
    "    func_name = cur_file_path.split('.txt')[0]\n",
    "    gas_pattern_path = 'cache/' + 'GAS_PATTERN_DISCOVERY_' + func_name + '.txt'\n",
    "\n",
    "    # Note: target codes at CODES_AFTER_CALLED_SIMILAR_FN_\n",
    "    if os.path.exists(gas_pattern_path):\n",
    "        print('pre cache_used')\n",
    "        \n",
    "    _, cache_used = discover_new_gas_pattern(append_texts, use_cache = True, cache_prefix = gas_pattern_path, collection_mode = False)\n",
    "\n",
    "\n",
    "    try:\n",
    "        _, cache_used = discover_new_gas_pattern(append_texts, use_cache = True, cache_prefix = gas_pattern_path, collection_mode = False)\n",
    "        #_, cache_used = use_called_and_similar_function_feedback(append_texts, use_cache = True, cache_prefix = 'prompts_folder/new_function_dataset_builder/deduplicated_by_func_name/' + 'CODES_AFTER_CALLED_SIMILAR_FN_' + func_name + '.txt', collection_mode = False)\n",
    "    except:\n",
    "        failed_lst_399023.append(func_name)\n",
    "        time.sleep(random.randint(30, 60))\n",
    "        continue\n",
    "            \n",
    "    if not cache_used:\n",
    "        time.sleep(random.randint(30, 60))\n",
    "    else:\n",
    "        print('cache_used')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0268e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3490a45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0x4ca725d446ece6e3ffd3e072a6f2a6a16ca492d0_NUMBER0',\n",
       " '0x29d078c18e73976710935e6789eb7a0151af7acd_NUMBER0',\n",
       " '0xcc5a1fb2999e5232310d15ef667ac5d4a5181258_NUMBER0',\n",
       " '0x340de5cb9b177ff1e3d00e6aa3082f979fca621e_NUMBER0',\n",
       " '0x1892038be4bd3968f4a8574593032d61c88dcacb_NUMBER0']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_lst_399023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f2f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8df2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b4cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "code_file_path = 'code_repository/Dispatcher.sol'\n",
    "code_file_path = 'code_repository/CarefulMath.sol'\n",
    "code_file_path = 'code_repository/RewardsCollector.sol'\n",
    "code_file_path = 'code_repository/LockAndMsgSender.sol'\n",
    "\n",
    "\n",
    "code_file_path_title = code_file_path.split('/')[-1].split('.')[0]\n",
    "\n",
    "target_patterns = read_from_file('gas_new_pattern_cache/extrapolate_patterns/' + code_file_path_title + '.txt')\n",
    "pattern_lst = target_patterns.split('*****&&&&&^^^^^%%%%%$$$$$')\n",
    "\n",
    "for p in pattern_lst:\n",
    "    new_patterns = check_new_gas_pattern(p, use_cache = True, cache_prefix = 'gas_new_pattern_cache/verify_found_patterns/' + code_file_path_title + '.txt', collection_mode = True)\n",
    "    time.sleep(random.randint(5, 15))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b401b8",
   "metadata": {},
   "source": [
    "Now that I have given you all of the necessary information, I want you to help me find new gas-wasting patterns in the above codes. Please put the new gas wasting patterns in bullet points (in the form of '1.', '2.', etc). Specifically, for each of the found patterns, I want you to answer each of the following questions, where the answer to each question should be put as a sub-bullet point under each bullet point:\n",
    "\n",
    "1. how did you find this pattern? Could you explain the reasoning process, step by step, behind the discovery?\n",
    "\n",
    "2. what should I do, step by step, to fix the found gas-wasting patterns? Could you explain the reasoning process, step by step, behind the reason why such a fix works?\n",
    "\n",
    "3. if you think my prompt to you has any issues (e.g. ambiguity or lack of information that could be beneficial for you to understand my task), please tell me how I should improve my prompt in the next time I ask you to perform the same task, such that you would be able to better understand my task and better solve it next time. If there are any suggestions, could you also explain the reasoning process, step by step, behind the reason why such a fix is needed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aebe7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70116d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa8896b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f3878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e2c09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
